include "base_train_config.conf"

ru_instruct_gpt4 = ${base_train} {
  "max_tokens": 1200,

  "train_loader": {
    "batch_size": 1,
  },

  "optimizer": {
    "lr": 1e-4
  },

  "model_type": "bfloat16",

  "peft": true,
  "lora_config": {
    "r": 2,
    "lora_alpha": 16,
    "lora_dropout": 0.1
  },

  "pretrained_path": "/s/ls4/groups/g0126/transformers_models/mistralai/Mistral-7B-Instruct-v0.2",
  "save_path": "/s/ls4/users/cappukan/projects/bot-of-the-gym/models/ruMistral-7B",
  "data_path": "data/prep/ru_instruct_gpt4.csv",

  "train_epochs": 5
}
